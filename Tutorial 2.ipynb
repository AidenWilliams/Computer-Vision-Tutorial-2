{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Area Processing (Tutorial 2)\n",
    "***\n",
    "# Table of Contents\n",
    "1.   [Imports](#Imports)\n",
    "2.   [Image Analysis](#Images-Analysis)\n",
    "3.   [Exercise 1 - Sliding Window](#Exercise-1---Sliding-Window)\n",
    "4.   [Exercise 2 - Convolution on RoI](#Exercise-2---Convolution-on-RoI)\n",
    "5.   [Exercise 3 - Convolution on the Whole Image](#Exercise-3---Convolution-on-the-Whole-Image)\n",
    "6.   [Exercise 4 - Different Convolution Kernels](#Exercise-4---Different-Convolution-Kernels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "\n",
    "Only 4 libraries are needed for this project:\n",
    "* opencv (cv2) - For image processing\n",
    "* numpy - For its arrays\n",
    "* matplotlib - Plotting histograms\n",
    "* os - File traversal\n",
    "* tqdm.notebook - tqdm progress bars, but for ipynb files\n",
    "* Classes - Custom classes written by me for this assignment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Classes import Window, Sobel, Gaussian, Bilinear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Analysis\n",
    "\n",
    "### aiden dp.jpg\n",
    "\n",
    "This is a picture of me in the upper barakka gardens in Valletta. The focus is myself with the background of the Grand\n",
    "Harbour. The picture is lighted by natural lighting and includes a lot of non linear features.\n",
    "\n",
    "<img src=\"images/aiden dp.jpg\">\n",
    "\n",
    "### cursed.jpg\n",
    "\n",
    "The image I will be using for this lab is one of my failed attempts of creating a pie chart for one of my statistics units\n",
    "from last year. It features a sun like object in the centre with black lines coming out from the centre, it is coloured in\n",
    "full RGB while the background is gray.\n",
    "\n",
    "<img src=\"images/cursed.jpg\">\n",
    "\n",
    "### dog chaos.png\n",
    "\n",
    "This is a blurry picture of two of my friends and another friend's dog. They are in a dimly lit, tiled floor room with a\n",
    "white wall and some furniture behind one of my friends.\n",
    "\n",
    "<img src=\"images/dog chaos.png\">\n",
    "\n",
    "### jake car.png\n",
    "\n",
    "This is a picture of my classmate Jake standing next to a red car. The photo was taken in a street during daytime. The\n",
    "background features several home facades, 2 other cars and a person.\n",
    "\n",
    "<img src=\"images/jake car.png\">\n",
    "\n",
    "### jake close up.jpg\n",
    "\n",
    "This is a picture of my classmate Jake with a beige background.\n",
    "\n",
    "<img src=\"images/jake close up.jpg\">\n",
    "\n",
    "### jake sitting.jpg\n",
    "\n",
    "This is a picture of my classmate Jake sitting on the floor of a bathroom. The room is well lit and tiled all over.\n",
    "\n",
    "<img src=\"images/jake sitting.jpg\">\n",
    "\n",
    "### jojo ben.jpg\n",
    "\n",
    "This is a picture of my classmate Ben walking towards the Hal Ghaxaq church with a bag of fried chicken in his hand. The\n",
    "photo was taken during the night so the lighting comes from old street lamps.\n",
    "\n",
    "<img src=\"images/jojo ben.jpg\">\n",
    "\n",
    "#### I have permission by all the people shown to use these images for this tutorial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I load the images into a list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading Images:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c501c743a01b41f6b492fead1eca11fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_images = []\n",
    "for file in tqdm(os.listdir(\"images\"), desc='Loading Images'):\n",
    "    raw_images.append(cv2.imread(\"images/\" + file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1 - Sliding Window\n",
    "\n",
    "### Window Class\n",
    "\n",
    "For this exercise I wrote the window class where I define some properties for the window.\n",
    "\n",
    "```python\n",
    "def __init__(self, image, n, s):\n",
    "    self.x_boundary = image.shape[1] + n\n",
    "    self.y_boundary = image.shape[0] + n\n",
    "    self.top_left = (0, 0)\n",
    "    self.bot_right = (n, n)\n",
    "    self.previousBotY = n\n",
    "    self.height = n\n",
    "    self.stride = (s, s)\n",
    "    try:\n",
    "        self.channels = image.shape[2]\n",
    "    except:\n",
    "        self.channels = 1\n",
    "```\n",
    "\n",
    "To create a Window, the image (min 2d numpy array), n (length or width) and s(stride or step) are required.\n",
    "\n",
    "Using these parameters I define:\n",
    "* The x and y boundaries for the window.\n",
    "* The starting top left and bottom right location as a tuple of two positions, where [0] is x and [1] is y.\n",
    "* Previous y position, this is used to check if the window has changed it's y position.\n",
    "* Height\n",
    "* Stride\n",
    "* Number of channels\n",
    "\n",
    "Each window is a square. The object is intended to be used for the image passed in initialisation.\n",
    "\n",
    "### Using Window for Ex 1\n",
    "\n",
    "For this exercise I use 4 functions from the class:\n",
    "\n",
    "```Python\n",
    "def getPos(self):\n",
    "    return self.top_left, self.bot_right\n",
    "```\n",
    "\n",
    "getPos returns the current position of the Window\n",
    "\n",
    "```python\n",
    "def forwardPos(self):\n",
    "    # Case when you need to go down and start new line\n",
    "    if (self.bot_right + self.stride)[0] >= (self.x_boundary - self.height):\n",
    "        return (0, self.top_left[1] + self.stride[1]), (self.height, self.bot_right[1] + self.stride[1])\n",
    "    # Generic move right case\n",
    "    else:\n",
    "        return (self.top_left[0] + self.stride[0], self.top_left[1]), \\\n",
    "               (self.bot_right[0] + self.stride[0], self.bot_right[1])\n",
    "```\n",
    "\n",
    "forwardPos returns the would be position of the next move. There are two cases:\n",
    "1. Next step stays in X boundary and so the new positions are just changed by adding stride\n",
    "2. Special case when next step would exceed X boundary so x positions are reset to 0, n and y positions are incremented\n",
    "by stride\n",
    "\n",
    "```python\n",
    "def forwardMove(self):\n",
    "    # Change positions\n",
    "    self.top_left, self.bot_right = self.forwardPos()\n",
    "    return self.top_left, self.bot_right\n",
    "```\n",
    "\n",
    "forwardMove changes the window's position to the return of forwardPos\n",
    "\n",
    "```python\n",
    "def inBoundary(self, new_top_left=None, new_bot_right=None):\n",
    "    # Use current position if no new positions are passed\n",
    "    if new_top_left is None:\n",
    "        new_top_left = self.top_left\n",
    "    if new_bot_right is None:\n",
    "        new_bot_right = self.bot_right\n",
    "    # Check if parameters are in boundary of the image given in initialisation\n",
    "    return new_bot_right[0] <= self.x_boundary and new_bot_right[1] <= self.y_boundary and \\\n",
    "           new_top_left[0] >= 0 and new_top_left[1] >= 0\n",
    "```\n",
    "\n",
    "inBoundary returns whether given positions, or the current positions are inBoundary of the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explenation\n",
    "\n",
    "First I initialise a Window for 'aiden dp.png' n=100, s=50. The reason for it being quite a \"large\" window is so that\n",
    "the sliding window demonstration can go fast.\n",
    "\n",
    "The starting and future positions are read using getPos and forwardPos. It is expected that win is initialised in boundary.\n",
    "\n",
    "Then I loop while win is in its boundary.\n",
    "\n",
    "* Every iteration I draw a rectangle on the image using cv2.rectangle.\n",
    "* If show is on I display this using imshow.\n",
    "* Then the positions are moved forwardMove and the future positions are taken again using forwardPos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# On/Off switch\n",
    "show = True\n",
    "\n",
    "win = Window(raw_images[0], 100, 50)\n",
    "start_point, end_point = win.getPos()\n",
    "\n",
    "new_tl, new_br = win.forwardPos()\n",
    "while win.inBoundary(new_br):\n",
    "    image = cv2.rectangle(raw_images[0].copy(), start_point, end_point, (255, 255, 255))\n",
    "    if show:\n",
    "        cv2.imshow(\"Sliding Window\", image)\n",
    "        cv2.waitKey(int(1/35*1000))\n",
    "    start_point, end_point = win.forwardMove()\n",
    "    new_tl, new_br = win.forwardPos()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2 - Convolution on RoI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# sobel = Sobel()\n",
    "#\n",
    "# win = Window(gray, 300, 1)\n",
    "#\n",
    "# image = cv2.imread(\"1mb pic.png\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#\n",
    "# roi = win.getImageInBoundary(image)\n",
    "# cv2.imwrite(\"Output/roi_before_filter.png\", roi, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "# filtered = sobel.filterImage(image, win)\n",
    "# cv2.imwrite(\"Output/roi_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3 - Convolution on the Whole Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4 - Different Convolution Kernels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Area Processing (Tutorial 2)\n",
    "***\n",
    "# Table of Contents\n",
    "1.   [Imports](#Imports)\n",
    "2.   [Image Analysis](#Images-Analysis)\n",
    "3.   [Exercise 1 - Sliding Window](#Exercise-1---Sliding-Window)\n",
    "4.   [Exercise 2 - Convolution on RoI](#Exercise-2---Convolution-on-RoI)\n",
    "5.   [Exercise 3 - Convolution on the Whole Image](#Exercise-3---Convolution-on-the-Whole-Image)\n",
    "6.   [Exercise 4 - Different Convolution Kernels](#Exercise-4---Different-Convolution-Kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "\n",
    "Only 4 libraries are needed for this project:\n",
    "* opencv (cv2) - For image processing\n",
    "* numpy - For its arrays\n",
    "* matplotlib - Plotting histograms\n",
    "* os - File traversal\n",
    "* tqdm.notebook - tqdm progress bars, but for ipynb files\n",
    "* Classes - Custom classes written by me for this assignment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Classes import Window, Sobel, Gaussian, Bilinear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Analysis\n",
    "\n",
    "### aiden dp.jpg\n",
    "\n",
    "This is a picture of me in the upper barakka gardens in Valletta. The focus is myself with the background of the Grand\n",
    "Harbour. The picture is lighted by natural lighting and includes a lot of non linear features.\n",
    "\n",
    "<img src=\"images/aiden dp.jpg\">\n",
    "\n",
    "### cursed.jpg\n",
    "\n",
    "The image I will be using for this lab is one of my failed attempts of creating a pie chart for one of my statistics units\n",
    "from last year. It features a sun like object in the centre with black lines coming out from the centre, it is coloured in\n",
    "full RGB while the background is gray.\n",
    "\n",
    "<img src=\"images/cursed.jpg\">\n",
    "\n",
    "### dog chaos.png\n",
    "\n",
    "This is a blurry picture of two of my friends and another friend's dog. They are in a dimly lit, tiled floor room with a\n",
    "white wall and some furniture behind one of my friends.\n",
    "\n",
    "<img src=\"images/dog chaos.png\">\n",
    "\n",
    "### jake car.png\n",
    "\n",
    "This is a picture of my classmate Jake standing next to a red car. The photo was taken in a street during daytime. The\n",
    "background features several home facades, 2 other cars and a person.\n",
    "\n",
    "<img src=\"images/jake car.png\">\n",
    "\n",
    "### jake close up.jpg\n",
    "\n",
    "This is a picture of my classmate Jake with a beige background.\n",
    "\n",
    "<img src=\"images/jake close up.jpg\">\n",
    "\n",
    "### jake sitting.jpg\n",
    "\n",
    "This is a picture of my classmate Jake sitting on the floor of a bathroom. The room is well lit and tiled all over.\n",
    "\n",
    "<img src=\"images/jake sitting.jpg\">\n",
    "\n",
    "### jojo ben.jpg\n",
    "\n",
    "This is a picture of my classmate Ben walking towards the Hal Ghaxaq church with a bag of fried chicken in his hand. The\n",
    "photo was taken during the night so the lighting comes from old street lamps.\n",
    "\n",
    "<img src=\"images/jojo ben.jpg\">\n",
    "\n",
    "#### I have permission by all the people shown to use these images for this tutorial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I load the images into a list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading Images:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc53a6a7fbe64faf8415c581eff3f82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_images = {}\n",
    "for file in tqdm(os.listdir(\"images\"), desc='Loading Images'):\n",
    "    raw_images[file] = cv2.imread(\"images/\" + file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1 - Sliding Window\n",
    "\n",
    "### Window Class\n",
    "\n",
    "For this exercise I wrote the window class where I define some properties for the window.\n",
    "\n",
    "```python\n",
    "def __init__(self, image, n, s):\n",
    "    self.x_boundary = image.shape[1] + n\n",
    "    self.y_boundary = image.shape[0] + n\n",
    "    self.top_left = (0, 0)\n",
    "    self.bot_right = (n, n)\n",
    "    self.previousBotY = n\n",
    "    self.height = n\n",
    "    self.stride = (s, s)\n",
    "    try:\n",
    "        self.channels = image.shape[2]\n",
    "    except:\n",
    "        self.channels = 1\n",
    "```\n",
    "\n",
    "To create a Window, the image (min 2d numpy array), n (length or width) and s(stride or step) are required.\n",
    "\n",
    "Using these parameters I define:\n",
    "* The x and y boundaries for the window.\n",
    "* The starting top left and bottom right location as a tuple of two positions, where [0] is x and [1] is y.\n",
    "* Previous y position, this is used to check if the window has changed it's y position.\n",
    "* Height\n",
    "* Stride\n",
    "* Number of channels\n",
    "\n",
    "Each window is a square. The object is intended to be used for the image passed in initialisation.\n",
    "\n",
    "### Using Window for Ex 1\n",
    "\n",
    "For this exercise I use 4 functions from the class:\n",
    "\n",
    "```Python\n",
    "def getPos(self):\n",
    "    return self.top_left, self.bot_right\n",
    "```\n",
    "\n",
    "getPos returns the current position of the Window\n",
    "\n",
    "```python\n",
    "def forwardPos(self):\n",
    "    # Case when you need to go down and start new line\n",
    "    if (self.bot_right + self.stride)[0] >= (self.x_boundary - self.height):\n",
    "        return (0, self.top_left[1] + self.stride[1]), (self.height, self.bot_right[1] + self.stride[1])\n",
    "    # Generic move right case\n",
    "    else:\n",
    "        return (self.top_left[0] + self.stride[0], self.top_left[1]), \\\n",
    "               (self.bot_right[0] + self.stride[0], self.bot_right[1])\n",
    "```\n",
    "\n",
    "forwardPos returns the would be position of the next move. There are two cases:\n",
    "1. Next step stays in X boundary and so the new positions are just changed by adding stride\n",
    "2. Special case when next step would exceed X boundary so x positions are reset to 0, n and y positions are incremented\n",
    "by stride\n",
    "\n",
    "```python\n",
    "def forwardMove(self):\n",
    "    # Change positions\n",
    "    self.top_left, self.bot_right = self.forwardPos()\n",
    "    return self.top_left, self.bot_right\n",
    "```\n",
    "\n",
    "forwardMove changes the window's position to the return of forwardPos\n",
    "\n",
    "```python\n",
    "def inBoundary(self, new_top_left=None, new_bot_right=None):\n",
    "    # Use current position if no new positions are passed\n",
    "    if new_top_left is None:\n",
    "        new_top_left = self.top_left\n",
    "    if new_bot_right is None:\n",
    "        new_bot_right = self.bot_right\n",
    "    # Check if parameters are in boundary of the image given in initialisation\n",
    "    return new_bot_right[0] <= self.x_boundary and new_bot_right[1] <= self.y_boundary and \\\n",
    "           new_top_left[0] >= 0 and new_top_left[1] >= 0\n",
    "```\n",
    "\n",
    "inBoundary returns whether given positions, or the current positions are inBoundary of the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Code Explanation\n",
    "\n",
    "First I initialise a Window for 'aiden dp.png' n=100, s=50. The reason for it being quite a \"large\" window is so that\n",
    "the sliding window demonstration can go fast.\n",
    "\n",
    "A rectangle is drawn over the initial positions and saved.\n",
    "\n",
    "rectangles are drawn in red.\n",
    "\n",
    "The starting and future positions are read using getPos and forwardPos. It is expected that win is initialised in boundary.\n",
    "\n",
    "Then I loop while win is in its boundary.\n",
    "\n",
    "* Every iteration I draw a rectangle on the image using cv2.rectangle.\n",
    "* If show is on I display this using imshow.\n",
    "* Then the positions are moved forwardMove and the future positions are taken again using forwardPos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# On/Off switch\n",
    "show = False\n",
    "\n",
    "win = Window(raw_images[\"aiden dp.png\"], 100, 50)\n",
    "start_point, end_point = win.getPos()\n",
    "\n",
    "image = cv2.rectangle(raw_images[\"aiden dp.png\"].copy(), start_point, end_point, (0, 0, 255))\n",
    "cv2.imwrite(\"Output/aidenrectangle.png\", image, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "new_tl, new_br = win.forwardPos()\n",
    "while win.inBoundary(new_br):\n",
    "    image = cv2.rectangle(raw_images[\"aiden dp.png\"].copy(), start_point, end_point, (0, 0, 255))\n",
    "    if show:\n",
    "        cv2.imshow(\"Sliding Window\", image)\n",
    "        cv2.waitKey(int(1/35*1000))\n",
    "    start_point, end_point = win.forwardMove()\n",
    "    new_tl, new_br = win.forwardPos()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A rectangle drawn using cv2.rectangle with the bounds taken from the Window object.\n",
    "\n",
    "<img src=\"Output/aidenrectangle.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2 - Convolution on RoI\n",
    "\n",
    "### Kernel Class\n",
    "\n",
    "For this exercise I wrote the window class where I define some properties for the window.\n",
    "\n",
    "```python\n",
    "def __init__(self, kernel, weight):\n",
    "    self.kernel = kernel\n",
    "    self.weight = weight\n",
    "```\n",
    "\n",
    "To create a Kernel, its kernel (numpy array) and weight  are required.\n",
    "\n",
    "Using these parameters I define:\n",
    "* The kernel which will be used to multiply and sum over a given area.\n",
    "* The weight which will be multiplied to the result of the kernel pass.\n",
    "\n",
    "Like the Window class, each Kernel is a square.\n",
    "\n",
    "\n",
    "### Using Kernel for Remaining Exercises\n",
    "\n",
    "For the remaining exercises I use the 2 functions from the class:\n",
    "\n",
    "```Python\n",
    "def filter(self, roi, axis=0, channels=1):\n",
    "    ret = []\n",
    "    if axis == 2:\n",
    "        for i in range(channels):\n",
    "            if channels == 1:\n",
    "                _filter = self.kernel * roi\n",
    "            else:\n",
    "                _filter = self.kernel * roi[:, :, i]\n",
    "            sum_of_filter1 = _filter.sum()\n",
    "            if channels == 1:\n",
    "                _filter = self.kernel.T * roi\n",
    "            else:\n",
    "                _filter = self.kernel.T * roi[:, :, i]\n",
    "            sum_of_filter2 = _filter.sum()\n",
    "            ret.append((((sum_of_filter1 ** 2) + (sum_of_filter2 ** 2)) ** (1 / 2)) * self.weight)\n",
    "\n",
    "        return np.array(ret)\n",
    "    else:\n",
    "        for i in range(channels):\n",
    "            if channels == 1:\n",
    "                _filter = self.kernel * roi\n",
    "            else:\n",
    "                _filter = self.kernel * roi[:, :, i]\n",
    "            ret.append(_filter.sum() * self.weight)\n",
    "\n",
    "        return np.array(ret)\n",
    "```\n",
    "\n",
    "The filter function takes a roi, the axis of operation, and number channels of roi. There are two main parts and both\n",
    "function similarly.\n",
    "\n",
    "#### roi and kernel must have the same shape, otherwise there will be a shape error in the multiplication stage\n",
    "\n",
    "When axis is 2:\n",
    "\n",
    "1. Loop over each channel.\n",
    "2. Multiply roi's pixels in the channel with the kernel.\n",
    "3. Sum these values.\n",
    "4. Multiply roi's pixels in the channel with the kernel's transpose.\n",
    "5. Sum these values.\n",
    "6. Get the magnitude of both these values by squaring, adding then getting their square root. (vector magnitude)\n",
    "7. Multiply this result with kernel's weight.\n",
    "8. Append each result of every channel to a list.\n",
    "9. Convert ret to a numpy array and return.\n",
    "\n",
    "When axis is not 2:\n",
    "\n",
    "1. Loop over each channel.\n",
    "2. Multiply roi's pixels in the channel with the kernel.\n",
    "3. Sum these values.\n",
    "4. Multiply this result with the kernel's weight.\n",
    "5. Append each result of every channel to a list\n",
    "6. Convert ret to a numpy array and return\n",
    "\n",
    "In any case the return of filter is a pixel.\n",
    "\n",
    "\n",
    "```Python\n",
    "def filterImage(self, image, stride=1, window=None, axis=0):\n",
    "    new_image = []\n",
    "    line = []\n",
    "    if window is None:\n",
    "        moving_kernel = Window(image, self.kernel.shape[0], stride)\n",
    "    else:\n",
    "        image = window.getImageInBoundary(image)\n",
    "        moving_kernel = Window(image, self.kernel.shape[0], stride)\n",
    "\n",
    "    new_tl, _ = moving_kernel.forwardPos()\n",
    "    while moving_kernel.inBoundary(new_tl):\n",
    "        roi = moving_kernel.getImageInBoundary(image)\n",
    "        if moving_kernel.changedY():\n",
    "            new_image.append(line)\n",
    "            line = []\n",
    "\n",
    "        line.append(self.filter(roi, axis, moving_kernel.channels))\n",
    "\n",
    "        moving_kernel.forwardMove()\n",
    "        new_tl, _ = moving_kernel.forwardPos()\n",
    "\n",
    "    return np.array(new_image)\n",
    "```\n",
    "\n",
    "The filterImage function takes an image, stride, a window if it is expected to function on a RoI, and the axis of\n",
    "operation.\n",
    "\n",
    "new_image and line are 2 lists i will use for this function. new_image will be the output of passing the kernel over the\n",
    "image/RoI and line will be used to represent a  line of pixels.\n",
    "\n",
    "The first thing I do is check whether window was defined or not. If it is defined then the function is expected to work\n",
    "on a RoI, defined by window, on image and not the entire image. Hence, if it is defined I use the getImageInBoundary from\n",
    "the Window Class (explained below) and assign image to it. In any case, a moving_kernel is defined for image, the kernel\n",
    "and stride.\n",
    "\n",
    "Similar to the way I move the rectangle in Ex 1 using the Window move functions, here I define a RoI using moving_kernel\n",
    "and getImageInBoundary for image. This gives me a nxn copy of the image in moving_kernel's boundary. n here is the width\n",
    "and height of the Kernel.\n",
    "\n",
    "Then I check if the y position of moving_kernel has changed, if it did then I append line to new_image and reset line.\n",
    "This should happen in the first iteration.\n",
    "\n",
    "After this I append the filtered roi using the filter function to line.\n",
    "\n",
    "The next steps relate to the moving of the kernel.\n",
    "\n",
    "Finally new_images is returned as a numpy array.\n",
    "\n",
    "### Using Window for Remaining Exercises\n",
    "\n",
    "For this exercise I use 2 new functions (the other 4 functions are explained above) from the class:\n",
    "\n",
    "```Python\n",
    "def changedY(self):\n",
    "    if self.previousBotY == self.bot_right[1]:\n",
    "        return False\n",
    "    else:\n",
    "        self.previousBotY = self.bot_right[1]\n",
    "        return True\n",
    "```\n",
    "\n",
    "changedY checks whether the y value of the bottom right corner of the window has changed or not.\n",
    "\n",
    "```python\n",
    "def getImageInBoundary(self, image):\n",
    "    new_image = []\n",
    "    for i in range(self.top_left[1], self.bot_right[1]):\n",
    "        if i >= image.shape[0]:\n",
    "            continue\n",
    "        new_image.append(image[i][self.top_left[0]: self.bot_right[0]])\n",
    "\n",
    "    if self.channels == 1:\n",
    "        return np.resize(np.array(new_image), (self.height, self.height))\n",
    "    else:\n",
    "        return np.resize(np.array(new_image), (self.height, self.height, self.channels))\n",
    "```\n",
    "\n",
    "getImageInBoundary returns a numpy array of the pixels of image in the boundary of the Window. This is done by looping\n",
    "from the y value of the top left corner to the y value of the bottom right corner. Then for each iteration, using list\n",
    "slicing I append the x values from left to right.\n",
    "\n",
    "The return is sized appropriate to the image's ndims size.\n",
    "\n",
    "### Kernels\n",
    "\n",
    "```python\n",
    "class Sobel:\n",
    "    def __init__(self, weight):\n",
    "        self.kernel = Kernel(np.array([[-1, 0, 1],\n",
    "                                       [-2, 0, 2],\n",
    "                                       [-1, 0, 1]]),\n",
    "                             weight)\n",
    "\n",
    "    def filterImage(self, image, stride=1, window=None, axis=2):\n",
    "        return self.kernel.filterImage(image, stride, window, axis)\n",
    "\n",
    "\n",
    "class Gaussian:\n",
    "    def __init__(self, size, weight):\n",
    "        fwhm = size // 2\n",
    "        x = np.arange(0, size, 1, float)\n",
    "        y = x[:, np.newaxis]\n",
    "        x0 = y0 = size // 2\n",
    "        self.kernel = Kernel(np.exp(-4 * np.log(2) * ((x - x0) ** 2 + (y - y0) ** 2) / fwhm ** 2), weight)\n",
    "\n",
    "    def filterImage(self, image, stride=1, window=None, axis=0):\n",
    "        return self.kernel.filterImage(image, stride, window, axis)\n",
    "\n",
    "\n",
    "class Bilinear:\n",
    "    def __init__(self, weight):\n",
    "        self.kernel = Kernel(np.array([[1, 2, 1],\n",
    "                                       [2, 4, 2],\n",
    "                                       [1, 2, 1]]),\n",
    "                             weight)\n",
    "\n",
    "    def filterImage(self, image, stride=1, window=None, axis=0):\n",
    "        return self.kernel.filterImage(image, stride, window, axis)\n",
    "```\n",
    "\n",
    "The kernels used in this tutorial are then defined as above. The sobel and bilinear kernels are hard coded, while the\n",
    "gaussian kernel uses the code provided in the lecture notes to generate a kernel for the given size. Weight is explained\n",
    "above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I initialise a sobel kernel, I give a neutral weight because I don't think it needs one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sobel = Sobel(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I loop over every image and get a roi using getImageInBoundary of shape (300,300).\n",
    "Then I filter this roi using the sobel(x+y) kernel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35c35765cca644858567033312a67241"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image in tqdm(raw_images):\n",
    "    win = Window(raw_images[image], 300, 1)\n",
    "    roi = win.getImageInBoundary(raw_images[image])\n",
    "    cv2.imwrite(\"Output/RoI/\"+ image +\"_before_filter.png\", roi, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    filtered = sobel.filterImage(image=raw_images[image], window=win, axis=2)\n",
    "    cv2.imwrite(\"Output/RoI/\"+ image +\"_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I copy the \"aiden dp.png\" image, apply grayscale to it then get a roi and filter it as above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture\n",
    "image = raw_images[\"aiden dp.png\"].copy()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "win = Window(image, 300, 1)\n",
    "roi = win.getImageInBoundary(image)\n",
    "cv2.imwrite(\"Output/RoI/aidendp_before_filter.png\", roi, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "filtered = sobel.filterImage(image=image, window=win)\n",
    "cv2.imwrite(\"Output/RoI/aidendp_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3 - Convolution on the Whole Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I loop over every image and apply the sobel(x+y) filter on them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78d9941739e14df1b1043bf3266824a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image in tqdm(raw_images):\n",
    "    filtered = sobel.filterImage(image=raw_images[image], axis=2)\n",
    "    cv2.imwrite(\"Output/Full Image/Sobel2/\"+ image +\"_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4 - Different Convolution Kernels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I initialise a bilinear kernel, I give it a weight of 1.8 because otherwise the image would be too bright."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "bileaner = Bilinear(1/8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I initialise a gaussian kernel, I give it a weight of 1.8 because otherwise the image would be too bright.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "gaussian = Gaussian(5, 1/8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I collect the filters into a dict to make the last step easier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "filters = {\"Sobel\":sobel,\n",
    "           \"Bilinear\":bileaner,\n",
    "           \"Gaussian\":gaussian}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Explanation\n",
    "\n",
    "I loop over every image and apply all the filters to them. However for the sobel kernel, instead of using the x+y here I\n",
    "use x and y seperately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d79234bdfe84b7e9f2e108b44f1afcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image in tqdm(raw_images):\n",
    "    for filter in filters:\n",
    "        if filter == \"Sobel\":\n",
    "            filtered = filters[filter].filterImage(image=raw_images[image], axis=0)\n",
    "            cv2.imwrite(\"Output/Full Image/Sobel0/\"+ image +\"_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "            filtered = filters[filter].filterImage(image=raw_images[image], axis=1)\n",
    "            cv2.imwrite(\"Output/Full Image/Sobel1/\"+ image +\"_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "        else:\n",
    "            filtered = filters[filter].filterImage(image=raw_images[image])\n",
    "            cv2.imwrite(\"Output/Full Image/\"+ filter + \"/\" + image +\"_after_filter.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}